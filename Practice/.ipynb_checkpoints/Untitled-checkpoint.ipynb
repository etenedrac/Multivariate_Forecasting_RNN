{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning (DL) - Practicum 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.layers import TimeDistributed, RepeatVector\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config_file(nfile, abspath=False):\n",
    "    \"\"\"\n",
    "    Read the configuration from a json file\n",
    "\n",
    "    :param abspath:\n",
    "    :param nfile:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ext = '.json' if 'json' not in nfile else ''\n",
    "    pre = '' if abspath else './'\n",
    "    fp = open(pre + nfile + ext, 'r')\n",
    "\n",
    "    s = ''\n",
    "\n",
    "    for l in fp:\n",
    "        s += l\n",
    "\n",
    "    return json.loads(s)\n",
    "\n",
    "def lagged_vector(data, lag=1, ahead=0):\n",
    "    \"\"\"\n",
    "    Returns a vector with columns that are the steps of the lagged time series\n",
    "    Last column is the value to predict\n",
    "\n",
    "    Because arrays start at 0, Ahead starts at 0 but actually means one step ahead\n",
    "\n",
    "    :param data:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lvect = []\n",
    "    for i in range(lag):\n",
    "        lvect.append(data[i: -lag - ahead + i])\n",
    "    lvect.append(data[lag + ahead:])\n",
    "\n",
    "    return np.stack(lvect, axis=1)\n",
    "\n",
    "\n",
    "def lagged_matrix(data, lag=1, ahead=0):\n",
    "    \"\"\"\n",
    "    Returns a matrix with columns that are the steps of the lagged time series\n",
    "    Last column is the value to predict\n",
    "    :param data:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lvect = []\n",
    "\n",
    "    for i in range(lag):\n",
    "        lvect.append(data[i: -lag - ahead + i, :])\n",
    "    lvect.append(data[lag + ahead:, :])\n",
    "    return np.stack(lvect, axis=1)\n",
    "\n",
    "\n",
    "def _generate_dataset_one_var(data, datasize, testsize, lag=1, ahead=1):\n",
    "    \"\"\"\n",
    "    Generates dataset assuming only one variable for prediction\n",
    "    Here ahead starts at 1 (I know it is confusing)\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    # print('DATA Dim =', data.shape)\n",
    "\n",
    "    wind_train = data[:datasize, :]\n",
    "    # print('Train Dim =', wind_train.shape)\n",
    "\n",
    "    train = lagged_vector(wind_train, lag=lag, ahead=ahead - 1)\n",
    "\n",
    "    train_x, train_y = train[:, :lag], train[:, -1:, 0]#El ultim element del lagged vector es el que volem predir\n",
    "\n",
    "    wind_test = data[datasize:datasize + testsize, 0].reshape(-1, 1)\n",
    "    test = lagged_vector(wind_test, lag=lag, ahead=ahead - 1)\n",
    "\n",
    "    test_x, test_y = test[:, :lag], test[:, -1:, 0]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "def _generate_dataset_multiple_var(data, datasize, testsize, lag=1, ahead=1, x_vars=None, y_vars=None):\n",
    "    \"\"\"\n",
    "    Generates dataset assuming there is more than one variable for prediction\n",
    "    Here ahead starts at 1 (I know it is confusing)\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    print('DATA Dim =', data.shape)\n",
    "\n",
    "    wind_train = data[:datasize, :]\n",
    "    print('Train Dim =', wind_train.shape)\n",
    "\n",
    "    train = lagged_matrix(wind_train, lag=lag, ahead=ahead - 1)\n",
    "\n",
    "    train_x, train_y = train[:, :lag, x_vars], train[:, -1:, y_vars]\n",
    "    train_y = train_y.reshape((train_x.shape[0],len(y_vars)))\n",
    "\n",
    "    wind_test = data[datasize:datasize + testsize, :]\n",
    "    test = lagged_matrix(wind_test, lag=lag, ahead=ahead - 1)\n",
    "\n",
    "    test_x, test_y = test[:, :lag, x_vars], test[:, -1:, y_vars]\n",
    "    test_y = test_y.reshape((test_x.shape[0],len(y_vars)))\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "def _generate_dataset_multiple_var_multistep(data, datasize, testsize, lag=1, ahead=1, n_steps_out=1, x_vars=None, y_vars=None):\n",
    "    \"\"\"\n",
    "    Generates dataset assuming there is more than one variable for prediction\n",
    "    Here ahead starts at 1 (I know it is confusing)\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    print('DATA Dim =', data.shape)\n",
    "\n",
    "    wind_train = data[:datasize, :]\n",
    "    print('Train Dim =', wind_train.shape)\n",
    "\n",
    "    train = lagged_matrix(wind_train, lag=lag+n_steps_out, ahead=ahead - 1)\n",
    "\n",
    "    train_x, train_y = train[:, :lag, x_vars], train[:, lag+1:, y_vars]\n",
    "\n",
    "    train_y = train_y.reshape((train_x.shape[0], n_steps_out,len(y_vars)))\n",
    "\n",
    "    wind_test = data[datasize:datasize + testsize, :]\n",
    "    test = lagged_matrix(wind_test, lag=lag+n_steps_out, ahead=ahead - 1)\n",
    "\n",
    "    test_x, test_y = test[:, :lag, x_vars], test[:, lag+1:, y_vars]\n",
    "    test_y = test_y.reshape((test_x.shape[0], n_steps_out,len(y_vars)))\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def generate_dataset(config, ahead=1, data_path=None):\n",
    "    \"\"\"\n",
    "    Generates the dataset for training, test and validation\n",
    "\n",
    "    :param ahead: number of steps ahead for prediction\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = config['dataset']\n",
    "    datanames = config['datanames']\n",
    "    datasize = config['datasize']\n",
    "    testsize = config['testsize']\n",
    "    nsteps_out = config['nstepsout']\n",
    "    x_vars = config['x_vars']\n",
    "    y_vars = config['y_vars']\n",
    "    vars = config['vars']\n",
    "    lag = config['lag']\n",
    "\n",
    "    airq = {}\n",
    "\n",
    "    # Reads numpy arrays for all sites and keep only selected columns\n",
    "\n",
    "    aqdata = np.load(data_path)\n",
    "    \n",
    "    airq['data'] = aqdata\n",
    "    if vars is not None:\n",
    "        airq['data'] = airq['data'][:, vars]\n",
    "\n",
    "    if dataset == 0:\n",
    "        return _generate_dataset_one_var(airq['data'][:, 0].reshape(-1, 1), datasize, testsize,\n",
    "                                         lag=lag, ahead=ahead)\n",
    "    \n",
    "    #Option to do multiple predictions from mulltiple data\n",
    "    elif dataset == 1:\n",
    "        return _generate_dataset_multiple_var(airq['data'][:, :], datasize, testsize,\n",
    "                                         lag=lag, ahead=ahead, x_vars=x_vars, y_vars=y_vars)\n",
    "    \n",
    "    elif dataset ==2:\n",
    "        return _generate_dataset_multiple_var_multistep(airq['data'][:, :], datasize, testsize,\n",
    "                                         lag=lag, ahead=ahead, n_steps_out=nsteps_out, x_vars=x_vars, y_vars=y_vars)\n",
    "    # Just add more options to generate datasets with more than one variable for predicting one value\n",
    "    # or a sequence of values\n",
    "\n",
    "    raise NameError('ERROR: No such dataset type')\n",
    "\n",
    "\n",
    "def architecture(neurons, drop, nlayers, activation, activation_r, rnntype, impl=1, multistep=False):\n",
    "    \"\"\"\n",
    "    RNN architecture\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    RNN = LSTM if rnntype == 'LSTM' else GRU\n",
    "    if rnntype == 'SimpleRNN':\n",
    "        model = Sequential()\n",
    "        if nlayers == 1:\n",
    "            model.add(SimpleRNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                          recurrent_dropout=drop, activation=activation))\n",
    "        else:\n",
    "            model.add(SimpleRNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                          recurrent_dropout=drop, activation=activation,\n",
    "                          return_sequences=True))\n",
    "            for i in range(1, nlayers - 1):\n",
    "                model.add(SimpleRNN(neurons, recurrent_dropout=drop, implementation=impl,\n",
    "                              activation=activation, return_sequences=True))\n",
    "            model.add(SimpleRNN(neurons, recurrent_dropout=drop, activation=activation,\n",
    "                          implementation=impl))\n",
    "    else:    \n",
    "        model = Sequential()\n",
    "        if nlayers == 1:\n",
    "            model.add(RNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                          recurrent_dropout=drop, activation=activation, recurrent_activation=activation_r))\n",
    "        else:\n",
    "            model.add(RNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                          recurrent_dropout=drop, activation=activation, recurrent_activation=activation_r,\n",
    "                          return_sequences=True))\n",
    "            for i in range(1, nlayers - 1):\n",
    "                model.add(RNN(neurons, recurrent_dropout=drop, implementation=impl,\n",
    "                              activation=activation, recurrent_activation=activation_r, return_sequences=True))\n",
    "            model.add(RNN(neurons, recurrent_dropout=drop, activation=activation,\n",
    "                          recurrent_activation=activation_r, implementation=impl))\n",
    "    \n",
    "    if multistep:\n",
    "        model.add(RepeatVector(train_y.shape[1]))\n",
    "        #model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(train_y.shape[2])))\n",
    "    else:\n",
    "        model.add(Dense(train_y.shape[1]))\n",
    "    #model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the architecture and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:  EXPERIMENT_12_1\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.332588). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.161320). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.101372). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.102010). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06587199534084048\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -3.562509483973706e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_2\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.110039). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06547007664939332\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -4.1708051431953305e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_3\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.174326). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06675434149531272\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -2.6401092904615446e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_4\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.113674). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.100125). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.100125). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.100125). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.105136). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.105136). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.105136). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.105136). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.124612). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.140376). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.140376). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.140376). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.164987). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.164987). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.143277). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.137837). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.132350). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.137837). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.132350). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.132350). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.132350). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.132350). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.131060). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.120172). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.129000). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103120). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103026). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.102775). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103026). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103740). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103841). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104147). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103745). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104147). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104479). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104479). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104479). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104734). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104708). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104402). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104306). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06771351812693122\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -4.7624091893755085e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_5\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.105207). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.101444). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06970491373001343\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -7.99204290483122e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_6\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.120205). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.222363). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.223307). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.222363). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.157502). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103795). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103795). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104073). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103795). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.104073). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.102340). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06728385470474181\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -3.697594714986792e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_7\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.113330). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE test=  0.0666892597921583\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -4.274581947331881e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_8\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.137572). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103925). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06705848632966559\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -6.031653593965686e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_9\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.114034). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.221092). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.219363). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.269802). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.219363). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.240975). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.219363). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.218947). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.218530). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.212342). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.212342). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.157456). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103793). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.125169). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06648191899508638\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -4.239714409961112e+31\n",
      "\n",
      "\n",
      "Experiment:  EXPERIMENT_12_10\n",
      "DATA Dim = (31642, 12)\n",
      "Train Dim = (25300, 12)\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.122024). Check your callbacks.\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.114906). Check your callbacks.\n",
      "\n",
      "MSE test=  0.06602469147853271\n",
      "MSE test persistence = 0.06522573412805915\n",
      "R2 test persistence = 0.6967526438927013\n",
      "R2 test=  -7.229691117279218e+31\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    j = i+1\n",
    "    args = {\n",
    "        'name':'EXPERIMENT_12_'+str(j),\n",
    "        'verbose':False,\n",
    "        'best':True,\n",
    "        'tboard':True,\n",
    "        'config':{\n",
    "            \"data\": {\n",
    "                \"datanames\": [\"data\"],\n",
    "                \"vars\": [0,1,2,3,4,5,6,7,8,9,10,11],\n",
    "                \"datasize\": 25300,\n",
    "                \"testsize\": 6342,\n",
    "                \"dataset\": 1,\n",
    "                \"nstepsout\":288,\n",
    "                \"lag\": 6,\n",
    "                \"ahead\": 1,\n",
    "                \"x_vars\": [0,1,2,3,4,5,6,7,8,9,10,11],\n",
    "                \"y_vars\": [0,1,2,3,4,5]\n",
    "            },\n",
    "            \"arch\": {\n",
    "                \"neurons\": 8,\n",
    "                #\"rnn\": \"SimpleRNN\",\n",
    "                \"rnn\": \"LSTM\",\n",
    "                #\"rnn\": \"GRU\",\n",
    "                \"drop\": 0.0,\n",
    "                \"nlayers\": 1,\n",
    "                \"activation\": \"tanh\",\n",
    "                \"activation_r\": \"hard_sigmoid\",\n",
    "                \"multistep\": False\n",
    "            },\n",
    "            \"training\": {\n",
    "                \"batch\": 500,\n",
    "                \"epochs\": 50,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"lrate\": 0.001\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    print('Experiment: ',args['name'])\n",
    "    verbose = 1 if args['verbose'] else 0\n",
    "    impl = 2\n",
    "\n",
    "    ahead = args['config']['data']['ahead']\n",
    "\n",
    "    if verbose:\n",
    "        print('-----------------------------------------------------------------------------')\n",
    "        print('Steps Ahead = %d ' % ahead)\n",
    "\n",
    "    # Data path:\n",
    "    aq_data_path = './data/data2.npy'\n",
    "\n",
    "    #Split in training and test\n",
    "    train_x, train_y, test_x, test_y = generate_dataset(args['config']['data'], ahead=ahead, data_path=aq_data_path)\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    # Model\n",
    "\n",
    "    model = architecture(neurons=args['config']['arch']['neurons'],\n",
    "                         drop=args['config']['arch']['drop'],\n",
    "                         nlayers=args['config']['arch']['nlayers'],\n",
    "                         activation=args['config']['arch']['activation'],\n",
    "                         activation_r=args['config']['arch']['activation_r'], rnntype=args['config']['arch']['rnn'], impl=impl,\n",
    "                        multistep=args['config']['arch']['multistep'])\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "        print('lag: ', args['config']['data']['lag'],\n",
    "              '/Neurons: ', args['config']['arch']['neurons'],\n",
    "              '/Layers: ', args['config']['arch']['nlayers'],\n",
    "              '/Activations:', args['config']['arch']['activation'], args['config']['arch']['activation_r'])\n",
    "        print('Tr:', train_x.shape, train_y.shape, 'Ts:', test_x.shape, test_y.shape)\n",
    "        print()\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    # Training\n",
    "\n",
    "    optimizer = args['config']['training']['optimizer']\n",
    "\n",
    "    if optimizer == 'rmsprop':\n",
    "        if 'lrate' in args['config']['training']:\n",
    "            optimizer = RMSprop(lr=args['config']['training']['lrate'])\n",
    "        else:\n",
    "            optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    cbacks = []\n",
    "\n",
    "    if args['tboard']:\n",
    "        tensorboard = TensorBoard(log_dir=\"logs/{}\".format(args['name']))\n",
    "        cbacks.append(tensorboard)\n",
    "\n",
    "    if args['best']:\n",
    "        modfile = './model{}.h5'.format(args['name'])\n",
    "        mcheck = ModelCheckpoint(filepath=modfile, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                 save_weights_only=False, mode='auto', period=1)\n",
    "        cbacks.append(mcheck)\n",
    "\n",
    "    model.fit(train_x, train_y, batch_size=args['config']['training']['batch'],\n",
    "              epochs=args['config']['training']['epochs'],\n",
    "              validation_data=(test_x, test_y),\n",
    "              verbose=verbose, callbacks=cbacks)\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    # Results\n",
    "\n",
    "    if args['best']:\n",
    "        model = load_model(modfile)\n",
    "\n",
    "    score = model.evaluate(test_x, test_y, batch_size=args['config']['training']['batch'], verbose=0)\n",
    "\n",
    "    print()\n",
    "    print('MSE test= ', score)\n",
    "    test_yp = model.predict(test_x, batch_size=args['config']['training']['batch'], verbose=0)\n",
    "    if args['config']['arch']['multistep']:\n",
    "        r2test = r2_score(test_y.reshape((args['config']['data']['testsize']-args['config']['data']['nstepsout']-args['config']['data']['lag'], -1)), \n",
    "                      test_yp.reshape((args['config']['data']['testsize']-args['config']['data']['nstepsout']-args['config']['data']['lag'], -1)))\n",
    "    else:\n",
    "        print('MSE test persistence =', mean_squared_error(test_y[ahead:], test_y[0:-ahead]))\n",
    "        r2test = r2_score(test_y, test_yp)\n",
    "        r2pers = r2_score(test_y[ahead:, :], test_y[0:-ahead, :])\n",
    "        print('R2 test persistence =', r2pers)\n",
    "        resfile = open('result.txt', 'a')\n",
    "        resfile.write('NAME = %s, DATAS= %d, LAG= %d, AHEAD= %d, RNN= %s, NLAY= %d, NNEUR= %d, DROP= %3.2f, ACT= %s, RACT= %s, '\n",
    "                      'OPT= %s, MSE= %3.5f, R2Test = %3.5f, R2pers = %3.5f\\n' %\n",
    "                      (args['name'],\n",
    "                       args['config']['data']['dataset'],\n",
    "                       args['config']['data']['lag'],\n",
    "                       args['config']['data']['ahead'],\n",
    "                       args['config']['arch']['rnn'],\n",
    "                       args['config']['arch']['nlayers'],\n",
    "                       args['config']['arch']['neurons'],\n",
    "                       args['config']['arch']['drop'],\n",
    "                       args['config']['arch']['activation'],\n",
    "                       args['config']['arch']['activation_r'],\n",
    "                       args['config']['training']['optimizer'],\n",
    "                       mean_squared_error(test_y[ahead:], test_y[0:-ahead]),\n",
    "                       r2test, r2pers\n",
    "                       ))\n",
    "        resfile.close()\n",
    "    print('R2 test= ', r2test)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results exeriments 3, 4 and 5 (comparing recurrent units):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3 (SimpleRNN): mean=0.06932690979, std=0.0008147144342447596\n",
      "Experiment 4 (LSTM): mean=0.0651518953771, std=0.0005958420260438794\n",
      "Experiment 5 (GRU): mean=0.0647758127764, std=0.0006423812622199252\n",
      "\n",
      "Statistical tests:\n",
      "P-value between 3 and 4:  8.782134765659256e-10\n",
      "P-value between 3 and 5:  2.293063116128389e-10\n",
      "P-value between 4 and 5:  0.2142519527375881\n"
     ]
    }
   ],
   "source": [
    "ex3 = [0.0702885, 0.0698503, 0.068926648, 0.0689567899, 0.06882927, 0.06800899, 0.0698788, 0.069624, 0.068284, 0.0706218]\n",
    "ex4 = [0.065104033759,0.065086519879,0.065374186293,0.06606917133,0.06425994090,0.065160629259,0.064823167516,0.066148472510,0.065208579683,0.064284252642]\n",
    "ex5 = [0.064711208771,0.064268316499,0.064549140001,0.06560491689,0.065434561352,0.065677783245,0.064509176975,0.063491246301,0.06503563564,0.064476142090]\n",
    "\n",
    "print('Experiment 3 (SimpleRNN): mean={}, std={}'.format(np.mean(ex3), np.std(ex3)))\n",
    "print('Experiment 4 (LSTM): mean={}, std={}'.format(np.mean(ex4), np.std(ex4)))\n",
    "print('Experiment 5 (GRU): mean={}, std={}'.format(np.mean(ex5), np.std(ex5)))\n",
    "print()\n",
    "print('Statistical tests:')\n",
    "statistic, p = stats.ttest_ind(ex3, ex4, equal_var = False)\n",
    "print('P-value between 3 and 4: ',p)\n",
    "statistic, p = stats.ttest_ind(ex3, ex5, equal_var = False)\n",
    "print('P-value between 3 and 5: ',p)\n",
    "statistic, p = stats.ttest_ind(ex4, ex5, equal_var = False)\n",
    "print('P-value between 4 and 5: ',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3 (SimpleRNN): mean=104.9, std=14.720394016465727\n",
      "Experiment 4 (LSTM): mean=119.4, std=30.437476899375216\n",
      "Experiment 5 (GRU): mean=119.3, std=7.950471684120383\n"
     ]
    }
   ],
   "source": [
    "ex5 = [60+46,120+8,60+56,120+5,60+55,60+56,120+13,60+51,60+57,120+6]\n",
    "ex4 = [60+40,60+43,120+50,60+47,180+9,60+43,60+45,60+45,60+49,60+43]\n",
    "ex3 = [60+39,60+40,60+41,60+39,60+39,120+29,60+40,60+40,60+41,60+41]\n",
    "print('Experiment 3 (SimpleRNN): mean={}, std={}'.format(np.mean(ex3), np.std(ex3)))\n",
    "print('Experiment 4 (LSTM): mean={}, std={}'.format(np.mean(ex4), np.std(ex4)))\n",
    "print('Experiment 5 (GRU): mean={}, std={}'.format(np.mean(ex5), np.std(ex5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results exeriments 6 and 7 (comparing lag):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex6 = [0.064544521164, 0.064573173834, 0.0671816517, 0.06518608620, 0.06616969068, 0.0681723778, 0.0659906549, 0.06724898523, 0.0680107645, 0.064508417852]\n",
    "ex7 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results exeriments 8 and 9 (comparing layer depth):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 8 (LSTM): mean=0.065836030457, std=0.0013746487692277989\n",
      "Experiment 9 (GRU): mean=0.066851314855, std=0.0008544805535459683\n",
      "\n",
      "Statistical tests:\n",
      "P-value between 4 and 8:  0.19527534962903093\n",
      "P-value between 4 and 9:  0.00015990364013512986\n",
      "P-value between 5 and 8:  0.05660285835285115\n",
      "P-value between 5 and 9:  2.174367904458802e-05\n",
      "P-value between 8 and 9:  0.0793448655083408\n"
     ]
    }
   ],
   "source": [
    "ex4 = [0.065104033759,0.065086519879,0.065374186293,0.06606917133,0.06425994090,0.065160629259,0.064823167516,0.066148472510,0.065208579683,0.064284252642]\n",
    "ex5 = [0.064711208771,0.064268316499,0.064549140001,0.06560491689,0.065434561352,0.065677783245,0.064509176975,0.063491246301,0.06503563564,0.064476142090]\n",
    "\n",
    "ex8 = [0.06633847372,0.06867757954,0.065555703599,0.064632198796,0.065394043569,0.065534148121,0.064773644439,0.065256058188,0.064208210938,0.06799024366]\n",
    "ex9 = [0.06638802220,0.06776956759,0.06857582754,0.06551856710,0.06760998399,0.06606791560,0.06658691154,0.06690377829,0.06639571663,0.06669685807]\n",
    "\n",
    "print('Experiment 8 (LSTM): mean={}, std={}'.format(np.mean(ex8), np.std(ex8)))\n",
    "print('Experiment 9 (GRU): mean={}, std={}'.format(np.mean(ex9), np.std(ex9)))\n",
    "print()\n",
    "print('Statistical tests:')\n",
    "statistic, p = stats.ttest_ind(ex4, ex8, equal_var = False)\n",
    "print('P-value between 4 and 8: ',p)\n",
    "statistic, p = stats.ttest_ind(ex4, ex9, equal_var = False)\n",
    "print('P-value between 4 and 9: ',p)\n",
    "statistic, p = stats.ttest_ind(ex5, ex8, equal_var = False)\n",
    "print('P-value between 5 and 8: ',p)\n",
    "statistic, p = stats.ttest_ind(ex5, ex9, equal_var = False)\n",
    "print('P-value between 5 and 9: ',p)\n",
    "statistic, p = stats.ttest_ind(ex8, ex9, equal_var = False)\n",
    "print('P-value between 8 and 9: ',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 8 (LSTM): mean=138.4, std=4.317406628984581\n",
      "Experiment 9 (GRU): mean=155.0, std=18.477012745571184\n"
     ]
    }
   ],
   "source": [
    "ex8 = [120+15,120+29,120+13,120+15,120+19,120+19,120+16,120+19,120+17,120+22]\n",
    "ex9 = [120+16,120+25,120+18,120+32,120+21,120+21,180+8,180+8,120+44,120+37]\n",
    "print('Experiment 8 (LSTM): mean={}, std={}'.format(np.mean(ex8), np.std(ex8)))\n",
    "print('Experiment 9 (GRU): mean={}, std={}'.format(np.mean(ex9), np.std(ex9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results exeriments 10, 11 and 12 (comparing number of units):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 10 (16-LSTM-1): mean=0.065404015571, std=0.0010319065377750473\n",
      "Experiment 11 (64-GRU-1): mean=0.06560559394900001, std=0.0007909108581842161\n",
      "Experiment 12 (8-GRU-1): mean=0.066905305618, std=0.001131794704751865\n",
      "Statistical tests:\n",
      "P-value between 4 and 10:  0.5355430906233059\n",
      "P-value between 4 and 11:  0.18741783636653073\n",
      "P-value between 4 and 12:  0.001112961073813509\n",
      "P-value between 10 and 11:  0.6477891587975152\n",
      "P-value between 10 and 12:  0.00879908489675361\n",
      "P-value between 11 and 12:  0.012168877619894145\n"
     ]
    }
   ],
   "source": [
    "ex4 = [0.065104033759,0.065086519879,0.065374186293,0.06606917133,0.06425994090,0.065160629259,0.064823167516,0.066148472510,0.065208579683,0.064284252642]\n",
    "\n",
    "ex10 = [0.06539966677,0.06451291433,0.0650349539,0.06342062253,0.06702626501,0.0662864150,0.06439023295,0.0664226764,0.06590704824,0.06563936058]\n",
    "ex11 = [0.06759049661,0.06507482560,0.06526857264,0.0650890127,0.06547051935,0.0652739467,0.06535641515,0.06604867044,0.06622054329,0.06466293701]\n",
    "ex12 = [0.06587199534,0.06547007664,0.06675434149,0.06771351812,0.06970491373,0.06728385470,0.0666892597,0.067058486,0.06648191899,0.06602469147]\n",
    "\n",
    "\n",
    "print('Experiment 10 (16-LSTM-1): mean={}, std={}'.format(np.mean(ex10), np.std(ex10)))\n",
    "print('Experiment 11 (64-GRU-1): mean={}, std={}'.format(np.mean(ex11), np.std(ex11)))\n",
    "print('Experiment 12 (8-GRU-1): mean={}, std={}'.format(np.mean(ex12), np.std(ex12)))\n",
    "\n",
    "print('Statistical tests:')\n",
    "statistic, p = stats.ttest_ind(ex4, ex10, equal_var = False)\n",
    "print('P-value between 4 and 10: ',p)\n",
    "statistic, p = stats.ttest_ind(ex4, ex11, equal_var = False)\n",
    "print('P-value between 4 and 11: ',p)\n",
    "statistic, p = stats.ttest_ind(ex4, ex12, equal_var = False)\n",
    "print('P-value between 4 and 12: ',p)\n",
    "statistic, p = stats.ttest_ind(ex10, ex11, equal_var = False)\n",
    "print('P-value between 10 and 11: ',p)\n",
    "statistic, p = stats.ttest_ind(ex10, ex12, equal_var = False)\n",
    "print('P-value between 10 and 12: ',p)\n",
    "statistic, p = stats.ttest_ind(ex11, ex12, equal_var = False)\n",
    "print('P-value between 11 and 12: ',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda dates: pd.datetime.strptime(dates, '%x %H:%M')\n",
    "\n",
    "data = pd.read_csv('./data/AtchisonUV_20150801_to_20151119.csv', parse_dates=['Date'], index_col='Date',date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benzene</th>\n",
       "      <th>CS2</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>Wind Direction</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Origin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-10 03:15:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>220.61</td>\n",
       "      <td>162.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-10 02:00:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>184.78</td>\n",
       "      <td>158.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-10 04:30:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>573.36</td>\n",
       "      <td>144.61</td>\n",
       "      <td>166.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-10 01:50:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>537.12</td>\n",
       "      <td>125.71</td>\n",
       "      <td>154.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-10 04:20:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>424.89</td>\n",
       "      <td>105.50</td>\n",
       "      <td>166.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Benzene  CS2  Ozone  SO2  Toluene  Xylene  \\\n",
       "Date                                                             \n",
       "2015-10-10 03:15:00      2.5  2.5    2.5  2.5     2.50  220.61   \n",
       "2015-10-10 02:00:00      2.5  2.5    2.5  2.5     2.50  184.78   \n",
       "2015-10-10 04:30:00      2.5  2.5    2.5  2.5   573.36  144.61   \n",
       "2015-10-10 01:50:00      2.5  2.5    2.5  2.5   537.12  125.71   \n",
       "2015-10-10 04:20:00      2.5  2.5    2.5  2.5   424.89  105.50   \n",
       "\n",
       "                     Wind Direction  Wind Speed Wind Origin  \n",
       "Date                                                         \n",
       "2015-10-10 03:15:00           162.0         6.0         SSE  \n",
       "2015-10-10 02:00:00           158.0         7.0         SSE  \n",
       "2015-10-10 04:30:00           166.0         5.0         SSE  \n",
       "2015-10-10 01:50:00           154.0         8.0         SSE  \n",
       "2015-10-10 04:20:00           166.0         5.0         SSE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benzene</th>\n",
       "      <th>CS2</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>Wind Direction</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Origin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-18 23:40:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.87</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-18 23:45:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.67</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ESE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-18 23:50:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.61</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ESE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-18 23:55:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.59</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-19 00:00:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.47</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Benzene  CS2  Ozone  SO2  Toluene  Xylene  \\\n",
       "Date                                                             \n",
       "2015-11-18 23:40:00      2.5  2.5  20.87  2.5      2.5     2.5   \n",
       "2015-11-18 23:45:00      2.5  2.5  20.67  2.5      2.5     2.5   \n",
       "2015-11-18 23:50:00      2.5  2.5  20.61  2.5      2.5     2.5   \n",
       "2015-11-18 23:55:00      2.5  2.5  20.59  2.5      2.5     2.5   \n",
       "2015-11-19 00:00:00      2.5  2.5  20.47  2.5      2.5     2.5   \n",
       "\n",
       "                     Wind Direction  Wind Speed Wind Origin  \n",
       "Date                                                         \n",
       "2015-11-18 23:40:00           154.0         2.0         SSE  \n",
       "2015-11-18 23:45:00           113.0         1.0         ESE  \n",
       "2015-11-18 23:50:00           107.0         2.0         ESE  \n",
       "2015-11-18 23:55:00           100.0         2.0           E  \n",
       "2015-11-19 00:00:00            86.0         2.0           E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_parser(wind):\n",
    "    if wind=='N':\n",
    "        return [1,0,0,0]\n",
    "    elif wind=='NNE':\n",
    "        return [.75,0,.25,0]\n",
    "    elif wind=='NE':\n",
    "        return [.5,0,.5,0]\n",
    "    elif wind=='ENE':\n",
    "        return [.25,0,.75,0]\n",
    "    elif wind=='E':\n",
    "        return [0,0,1,0]\n",
    "    elif wind=='ESE':\n",
    "        return [0,.25,.75,0]\n",
    "    elif wind=='SE':\n",
    "        return [0,.5,.5,0]\n",
    "    elif wind=='SSE':\n",
    "        return [0,.75,.25,0]\n",
    "    elif wind=='S':\n",
    "        return [0,1,0,0]\n",
    "    elif wind=='SSW':\n",
    "        return [0,.75,0,.25]\n",
    "    elif wind=='SW':\n",
    "        return [0,.5,0,.5]\n",
    "    elif wind=='WSW':\n",
    "        return [0,.25,0,.75]\n",
    "    elif wind=='W':\n",
    "        return [0,0,0,1]\n",
    "    elif wind=='WNW':\n",
    "        return [.25,0,0,.75]\n",
    "    elif wind=='NW':\n",
    "        return [.5,0,0,.5]\n",
    "    elif wind=='NNW':\n",
    "        return [.75,0,0,.25]\n",
    "    else:\n",
    "        return [0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "builds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
