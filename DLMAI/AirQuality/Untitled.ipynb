{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import argparse\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".. module:: WindPrediction\n",
    "\n",
    "WindPrediction\n",
    "*************\n",
    "\n",
    ":Description: WindPrediction\n",
    "\n",
    ":Authors: bejar\n",
    "    \n",
    "\n",
    ":Version: \n",
    "\n",
    ":Created on: 06/09/2017 9:47 \n",
    "\n",
    "\"\"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "__author__ = 'bejar'\n",
    "\n",
    "\n",
    "def load_config_file(nfile, abspath=False):\n",
    "    \"\"\"\n",
    "    Read the configuration from a json file\n",
    "\n",
    "    :param abspath:\n",
    "    :param nfile:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ext = '.json' if 'json' not in nfile else ''\n",
    "    pre = '' if abspath else './'\n",
    "    fp = open(pre + nfile + ext, 'r')\n",
    "\n",
    "    s = ''\n",
    "\n",
    "    for l in fp:\n",
    "        s += l\n",
    "\n",
    "    return json.loads(s)\n",
    "\n",
    "def lagged_vector(data, lag=1, ahead=0):\n",
    "    \"\"\"\n",
    "    Returns a vector with columns that are the steps of the lagged time series\n",
    "    Last column is the value to predict\n",
    "\n",
    "    Because arrays start at 0, Ahead starts at 0 but actually means one step ahead\n",
    "\n",
    "    :param data:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lvect = []\n",
    "    for i in range(lag):\n",
    "        lvect.append(data[i: -lag - ahead + i])\n",
    "    lvect.append(data[lag + ahead:])\n",
    "\n",
    "    return np.stack(lvect, axis=1)\n",
    "\n",
    "\n",
    "def lagged_matrix(data, lag=1, ahead=0):\n",
    "    \"\"\"\n",
    "    Returns a matrix with columns that are the steps of the lagged time series\n",
    "    Last column is the value to predict\n",
    "    :param data:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lvect = []\n",
    "\n",
    "    for i in range(lag):\n",
    "        lvect.append(data[i: -lag - ahead + i, :])\n",
    "    lvect.append(data[lag + ahead:, :])\n",
    "    return np.stack(lvect, axis=1)\n",
    "\n",
    "\n",
    "def _generate_dataset_one_var(data, datasize, testsize, lag=1, ahead=1):\n",
    "    \"\"\"\n",
    "    Generates dataset assuming only one variable for prediction\n",
    "    Here ahead starts at 1 (I know it is confusing)\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    # print('DATA Dim =', data.shape)\n",
    "\n",
    "    wind_train = data[:datasize, :]\n",
    "    # print('Train Dim =', wind_train.shape)\n",
    "\n",
    "    train = lagged_vector(wind_train, lag=lag, ahead=ahead - 1)\n",
    "\n",
    "    train_x, train_y = train[:, :lag], train[:, -1:, 0]\n",
    "\n",
    "    wind_test = data[datasize:datasize + testsize, 0].reshape(-1, 1)\n",
    "    test = lagged_vector(wind_test, lag=lag, ahead=ahead - 1)\n",
    "\n",
    "    test_x, test_y = test[:, :lag], test[:, -1:, 0]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def generate_dataset(config, ahead=1, data_path=None):\n",
    "    \"\"\"\n",
    "    Generates the dataset for training, test and validation\n",
    "\n",
    "    :param ahead: number of steps ahead for prediction\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = config['dataset']\n",
    "    datanames = config['datanames']\n",
    "    datasize = config['datasize']\n",
    "    testsize = config['testsize']\n",
    "    vars = config['vars']\n",
    "    lag = config['lag']\n",
    "\n",
    "    airq = {}\n",
    "\n",
    "    # Reads numpy arrays for all sites and keep only selected columns\n",
    "\n",
    "    aqdata = np.load(data_path + 'LondonAQ.npz')\n",
    "    for d in datanames:\n",
    "        airq[d] = aqdata[d]\n",
    "        if vars is not None:\n",
    "            airq[d] = airq[d][:, vars]\n",
    "\n",
    "    if dataset == 0:\n",
    "        return _generate_dataset_one_var(airq[datanames[0]][:, 0].reshape(-1, 1), datasize, testsize,\n",
    "                                         lag=lag, ahead=ahead)\n",
    "    # Just add more options to generate datasets with more than one variable for predicting one value\n",
    "    # or a sequence of values\n",
    "\n",
    "    raise NameError('ERROR: No such dataset type')\n",
    "\n",
    "\n",
    "def architecture(neurons, drop, nlayers, activation, activation_r, rnntype, impl=1):\n",
    "    \"\"\"\n",
    "    RNN architecture\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    RNN = LSTM if rnntype == 'LSTM' else GRU\n",
    "    model = Sequential()\n",
    "    if nlayers == 1:\n",
    "        model.add(RNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                      recurrent_dropout=drop, activation=activation, recurrent_activation=activation_r))\n",
    "    else:\n",
    "        model.add(RNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                      recurrent_dropout=drop, activation=activation, recurrent_activation=activation_r,\n",
    "                      return_sequences=True))\n",
    "        for i in range(1, nlayers - 1):\n",
    "            model.add(RNN(neurons, recurrent_dropout=drop, implementation=impl,\n",
    "                          activation=activation, recurrent_activation=activation_r, return_sequences=True))\n",
    "        model.add(RNN(neurons, recurrent_dropout=drop, activation=activation,\n",
    "                      recurrent_activation=activation_r, implementation=impl))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'datanames': ['GEltham', 'GWesthorne', 'BSladeGreen', 'GWoolwich'],\n",
       "  'vars': [0, 1, 2, 3, 4],\n",
       "  'datasize': 35064,\n",
       "  'testsize': 8784,\n",
       "  'dataset': 0,\n",
       "  'lag': 6,\n",
       "  'ahead': 1},\n",
       " 'arch': {'neurons': 32,\n",
       "  'rnn': 'LSTM',\n",
       "  'drop': 0.0,\n",
       "  'nlayers': 1,\n",
       "  'activation': 'tanh',\n",
       "  'activation_r': 'hard_sigmoid'},\n",
       " 'training': {'batch': 500, 'epochs': 25, 'optimizer': 'adam', 'lrate': 0.001}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    'config': 'config',\n",
    "    'verbose': True,\n",
    "    'best': True,\n",
    "    'tboard': True\n",
    "}\n",
    "\n",
    "verbose = 1 if args['verbose'] else 0\n",
    "impl = 2\n",
    "\n",
    "config = load_config_file(args['config'])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "Steps Ahead = 1 \n"
     ]
    }
   ],
   "source": [
    "ahead = config['data']['ahead']\n",
    "\n",
    "if args['verbose']:\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    print('Steps Ahead = %d ' % ahead)\n",
    "\n",
    "# Modify conveniently with the path for your data\n",
    "aq_data_path = './'\n",
    "\n",
    "train_x, train_y, test_x, test_y = generate_dataset(config['data'], ahead=ahead, data_path=aq_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "Steps Ahead = 1 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "lag:  6 /Neurons:  32 /Layers:  1 /Activations: tanh hard_sigmoid\n",
      "Tr: (35058, 6, 1) (35058, 1) Ts: (8778, 6, 1) (8778, 1)\n",
      "\n",
      "Train on 35058 samples, validate on 8778 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(500, 1), b.shape=(1, 128), m=500, n=128, k=1\n\t [[{{node lstm/while/MatMul}} = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/lstm/while/MatMul_grad/MatMul_1\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm/while/TensorArrayReadV3, lstm/while/MatMul/ReadVariableOp)]]\n\t [[{{node loss/dense_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_2/_93}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1059_...t/Switch_2\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-31cfefb436bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m           verbose=verbose, callbacks=cbacks)\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m############################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\builds\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\builds\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\builds\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\builds\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\builds\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(500, 1), b.shape=(1, 128), m=500, n=128, k=1\n\t [[{{node lstm/while/MatMul}} = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/lstm/while/MatMul_grad/MatMul_1\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm/while/TensorArrayReadV3, lstm/while/MatMul/ReadVariableOp)]]\n\t [[{{node loss/dense_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_2/_93}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1059_...t/Switch_2\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--config', default='config', help='Experiment configuration')\n",
    "# parser.add_argument('--verbose', help=\"Verbose output (enables Keras verbose output)\", action='store_true',\n",
    "#                     default=False)\n",
    "# parser.add_argument('--best', help=\"Save weights best in test\", action='store_true', default=False)\n",
    "# parser.add_argument('--tboard', help=\"Save log for tensorboard\", action='store_true', default=False)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = {\n",
    "    'config': 'config',\n",
    "    'verbose': True,\n",
    "    'best': True,\n",
    "    'tboard': True\n",
    "}\n",
    "\n",
    "verbose = 1 if args['verbose'] else 0\n",
    "impl = 2\n",
    "\n",
    "config = load_config_file(args['config'])\n",
    "############################################\n",
    "# Data\n",
    "\n",
    "ahead = config['data']['ahead']\n",
    "\n",
    "if args['verbose']:\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    print('Steps Ahead = %d ' % ahead)\n",
    "\n",
    "# Modify conveniently with the path for your data\n",
    "aq_data_path = './'\n",
    "\n",
    "train_x, train_y, test_x, test_y = generate_dataset(config['data'], ahead=ahead, data_path=aq_data_path)\n",
    "\n",
    "############################################\n",
    "# Model\n",
    "\n",
    "model = architecture(neurons=config['arch']['neurons'],\n",
    "                     drop=config['arch']['drop'],\n",
    "                     nlayers=config['arch']['nlayers'],\n",
    "                     activation=config['arch']['activation'],\n",
    "                     activation_r=config['arch']['activation_r'], rnntype=config['arch']['rnn'], impl=impl)\n",
    "if args['verbose']:\n",
    "    model.summary()\n",
    "    print('lag: ', config['data']['lag'],\n",
    "          '/Neurons: ', config['arch']['neurons'],\n",
    "          '/Layers: ', config['arch']['nlayers'],\n",
    "          '/Activations:', config['arch']['activation'], config['arch']['activation_r'])\n",
    "    print('Tr:', train_x.shape, train_y.shape, 'Ts:', test_x.shape, test_y.shape)\n",
    "    print()\n",
    "\n",
    "############################################\n",
    "# Training\n",
    "\n",
    "optimizer = config['training']['optimizer']\n",
    "\n",
    "if optimizer == 'rmsprop':\n",
    "    if 'lrate' in config['training']:\n",
    "        optimizer = RMSprop(lr=config['training']['lrate'])\n",
    "    else:\n",
    "        optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "cbacks = []\n",
    "\n",
    "if args['tboard']:\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "    cbacks.append(tensorboard)\n",
    "\n",
    "if args['best']:\n",
    "    modfile = './model%d.h5' % int(time())\n",
    "    mcheck = ModelCheckpoint(filepath=modfile, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "    cbacks.append(mcheck)\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=config['training']['batch'],\n",
    "          epochs=config['training']['epochs'],\n",
    "          validation_data=(test_x, test_y),\n",
    "          verbose=verbose, callbacks=cbacks)\n",
    "\n",
    "############################################\n",
    "# Results\n",
    "\n",
    "if args['best']:\n",
    "    model = load_model(modfile)\n",
    "\n",
    "score = model.evaluate(test_x, test_y, batch_size=config['training']['batch'], verbose=0)\n",
    "\n",
    "print()\n",
    "print('MSE test= ', score)\n",
    "print('MSE test persistence =', mean_squared_error(test_y[ahead:], test_y[0:-ahead]))\n",
    "test_yp = model.predict(test_x, batch_size=config['training']['batch'], verbose=0)\n",
    "r2test = r2_score(test_y, test_yp)\n",
    "r2pers = r2_score(test_y[ahead:, 0], test_y[0:-ahead, 0])\n",
    "print('R2 test= ', r2test)\n",
    "print('R2 test persistence =', r2pers)\n",
    "\n",
    "resfile = open('result-%s.txt' % config['data']['datanames'][0], 'a')\n",
    "resfile.write('DATAS= %d, LAG= %d, AHEAD= %d, RNN= %s, NLAY= %d, NNEUR= %d, DROP= %3.2f, ACT= %s, RACT= %s, '\n",
    "              'OPT= %s, R2Test = %3.5f, R2pers = %3.5f\\n' %\n",
    "              (config['data']['dataset'],\n",
    "               config['data']['lag'],\n",
    "               config['data']['ahead'],\n",
    "               config['arch']['rnn'],\n",
    "               config['arch']['nlayers'],\n",
    "               config['arch']['neurons'],\n",
    "               config['arch']['drop'],\n",
    "               config['arch']['activation'],\n",
    "               config['arch']['activation_r'],\n",
    "               config['training']['optimizer'],\n",
    "               r2test, r2pers\n",
    "               ))\n",
    "resfile.close()\n",
    "\n",
    "# Deletes the model file\n",
    "try:\n",
    "    os.remove(modfile)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "builds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
